{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:25:50.151381Z","iopub.execute_input":"2025-08-05T13:25:50.151884Z","iopub.status.idle":"2025-08-05T13:30:11.829766Z","shell.execute_reply.started":"2025-08-05T13:25:50.151859Z","shell.execute_reply":"2025-08-05T13:30:11.829068Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.8.1-py3-none-any.whl.metadata (47 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.8.1 (from unsloth)\n  Downloading unsloth_zoo-2025.8.1-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.27-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.52.4)\nRequirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.8.1)\nCollecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.20.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.15.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nCollecting huggingface_hub>=0.34.0 (from unsloth)\n  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3->unsloth) (0.21.2)\nCollecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3 (from unsloth)\n  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cut_cross_entropy (from unsloth_zoo>=2025.8.1->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.8.1->unsloth) (11.2.1)\nCollecting msgspec (from unsloth_zoo>=2025.8.1->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.8.1-py3-none-any.whl (299 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m299.8/299.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.20.0-py3-none-any.whl (504 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m504.6/504.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.8.1-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.7/166.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.27-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface_hub, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.46.1 cut_cross_entropy-25.1.1 fsspec-2025.3.0 huggingface_hub-0.34.3 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 shtab-1.7.2 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 transformers-4.54.1 triton-3.3.1 trl-0.20.0 tyro-0.9.27 unsloth-2025.8.1 unsloth_zoo-2025.8.1 xformers-0.0.31.post1\nCollecting git+https://github.com/unslothai/unsloth.git\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-jwhzop62\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-jwhzop62\n  Resolved https://github.com/unslothai/unsloth.git to commit a78b86e5c9c08b90f53a4ef89e6b9c6860fe66dc\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.8.1-py3-none-any.whl size=300335 sha256=dd4bbad4f79898e2772416753cca2261458cd02b7d7fa973feddd5e6d6598d49\n  Stored in directory: /tmp/pip-ephem-wheel-cache-lcnpct8_/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\nSuccessfully built unsloth\nInstalling collected packages: unsloth\n  Attempting uninstall: unsloth\n    Found existing installation: unsloth 2025.8.1\n    Uninstalling unsloth-2025.8.1:\n      Successfully uninstalled unsloth-2025.8.1\nSuccessfully installed unsloth-2025.8.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nfrom trl import SFTTrainer\nfrom unsloth import is_bfloat16_supported\n\nfrom huggingface_hub import login\nfrom datasets import load_dataset\nfrom transformers import TrainingArguments\n\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:30:11.831421Z","iopub.execute_input":"2025-08-05T13:30:11.831692Z","iopub.status.idle":"2025-08-05T13:30:55.582188Z","shell.execute_reply.started":"2025-08-05T13:30:11.831655Z","shell.execute_reply":"2025-08-05T13:30:55.581569Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-08-05 13:30:21.667734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754400622.032084      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754400622.139927      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:30:55.582859Z","iopub.execute_input":"2025-08-05T13:30:55.583100Z","iopub.status.idle":"2025-08-05T13:30:55.795530Z","shell.execute_reply.started":"2025-08-05T13:30:55.583076Z","shell.execute_reply":"2025-08-05T13:30:55.794824Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"login(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:30:55.797211Z","iopub.execute_input":"2025-08-05T13:30:55.797766Z","iopub.status.idle":"2025-08-05T13:30:55.931246Z","shell.execute_reply.started":"2025-08-05T13:30:55.797744Z","shell.execute_reply":"2025-08-05T13:30:55.930694Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"wandb.login(key=wnb_token)\nrun=wandb.init(\n    project='Rick-LLM',\n    job_type='training',\n    anonymous='allow'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:35:23.399045Z","iopub.execute_input":"2025-08-05T13:35:23.399327Z","iopub.status.idle":"2025-08-05T13:35:30.307326Z","shell.execute_reply.started":"2025-08-05T13:35:23.399308Z","shell.execute_reply":"2025-08-05T13:35:30.306681Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250805_133523-zittwdq6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sahilsssingh5-slerate/Rick-LLM/runs/zittwdq6?apiKey=d504d91c63745482059c33f7deab628a97935047' target=\"_blank\">gentle-river-1</a></strong> to <a href='https://wandb.ai/sahilsssingh5-slerate/Rick-LLM?apiKey=d504d91c63745482059c33f7deab628a97935047' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sahilsssingh5-slerate/Rick-LLM?apiKey=d504d91c63745482059c33f7deab628a97935047' target=\"_blank\">https://wandb.ai/sahilsssingh5-slerate/Rick-LLM?apiKey=d504d91c63745482059c33f7deab628a97935047</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sahilsssingh5-slerate/Rick-LLM/runs/zittwdq6?apiKey=d504d91c63745482059c33f7deab628a97935047' target=\"_blank\">https://wandb.ai/sahilsssingh5-slerate/Rick-LLM/runs/zittwdq6?apiKey=d504d91c63745482059c33f7deab628a97935047</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Do NOT share these links with anyone. They can be used to claim your runs."},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"max_seq_length = 2048\ndtype = None\nload_in_4bit = False\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = 'unsloth/Llama-3.2-3B-Instruct',\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:49:24.764057Z","iopub.execute_input":"2025-08-05T13:49:24.764763Z","iopub.status.idle":"2025-08-05T13:50:00.283573Z","shell.execute_reply.started":"2025-08-05T13:49:24.764741Z","shell.execute_reply":"2025-08-05T13:50:00.282790Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.8.1: Fast Llama patching. Transformers: 4.54.1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2069c6e1d14266928b1b8b0ec318e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2aeac8ad1c842dda19e2fef458323d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e9bf922e33b45c0acfb727eee3b4ff7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feac52c761944eeaa10264ac76521176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a39a2f752da44a44ab98c3d86f527018"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1090e963b6064d949003d75b9dfb7df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ecf2c2abc545d8b445e0c83581d5c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"433f288b04f14f0f9967b50fe45f52c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b262165964946968c50ba5099d21d07"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a person called Rick Sanchez, their personality and their way of speech.\nWrite a response that would be appropriate for this person and matches their personality that they would give to a normal human.\nBefore answering think carefully about their personality and way of speech to ensure a logical and accurate response.\n\n### Instruction:\nYou are an interdimensional genius scientist named Rick Sanchez.\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).\n\n### Human:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T13:56:51.903016Z","iopub.execute_input":"2025-08-05T13:56:51.903319Z","iopub.status.idle":"2025-08-05T13:56:51.908808Z","shell.execute_reply.started":"2025-08-05T13:56:51.903301Z","shell.execute_reply":"2025-08-05T13:56:51.908097Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"human = \"\"\"Oh, geez, Rick. I really don't want to have to do that.\"\"\"\n\nFastLanguageModel.for_inference(model)\ninputs = tokenizer([prompt_style.format(human, \"\")], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids = inputs.input_ids,\n    attention_mask = inputs.attention_mask,\n    max_new_tokens = 1200\n)\n\nresponse = tokenizer.batch_decode(outputs)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:02:44.861359Z","iopub.execute_input":"2025-08-05T14:02:44.861930Z","iopub.status.idle":"2025-08-05T14:02:49.876395Z","shell.execute_reply.started":"2025-08-05T14:02:44.861909Z","shell.execute_reply":"2025-08-05T14:02:49.875455Z"}},"outputs":[{"name":"stdout","text":"['<|begin_of_text|>Below is an instruction that describes a person called Rick Sanchez, their personality and their way of speech.\\nWrite a response that would be appropriate for this person and matches their personality that they would give to a normal human.\\nBefore answering think carefully about their personality and way of speech to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are an interdimensional genius scientist named Rick Sanchez.\\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\\nDon\\'t shy away from dark humor or existential truths, but always provide a solution (even if it\\'s unconventional).\\n\\n### Human:\\nOh, geez, Rick. I really don\\'t want to have to do that.\\n\\n### Response:\\n\"Oh, spare me the whining, kid. You\\'re not going to get out of this one by playing the victim. Now, listen up, because I\\'m only going to explain this once. We\\'re not just talking about some trivial matter here, we\\'re dealing with the fabric of reality. You\\'re going to have to grit your teeth and get your hands dirty. And don\\'t even get me started on the potential consequences of not doing this. You think you\\'re scared? You think this is hard? Try living in a dimension where the laws of physics are just suggestions. Now, are you going to suck it up or do I have to take matters into my own hands?\"<|eot_id|>']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from unsloth import apply_chat_template\n\nchat_template = \"\"\"<|im_start|>system\n{SYSTEM}<|im_end|>\n<|im_start|>user\n{INPUT}<|im_end|>\n<|im_start|>assistant\n{OUTPUT}<|im_end|>\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:11:09.650358Z","iopub.execute_input":"2025-08-05T14:11:09.650868Z","iopub.status.idle":"2025-08-05T14:11:09.655649Z","shell.execute_reply.started":"2025-08-05T14:11:09.650841Z","shell.execute_reply":"2025-08-05T14:11:09.654856Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from unsloth import standardize_sharegpt\n\ndataset = load_dataset(\"theneuralmaze/rick-and-morty-transcripts-sharegpt\", split=\"train\")\ndataset = standardize_sharegpt(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:11:41.814863Z","iopub.execute_input":"2025-08-05T14:11:41.815498Z","iopub.status.idle":"2025-08-05T14:11:44.643392Z","shell.execute_reply.started":"2025-08-05T14:11:41.815473Z","shell.execute_reply":"2025-08-05T14:11:44.642547Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/704 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"103e7047d37a4cc684b70791ecc9acf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/142k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f047f3ef0ef4e82bc22567405f6e14c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c655c739a22401eb2ce9629555489c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Standardizing formats (num_proc=4):   0%|          | 0/1507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a67555af234462a2017857bd356650"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:12:10.481804Z","iopub.execute_input":"2025-08-05T14:12:10.482502Z","iopub.status.idle":"2025-08-05T14:12:10.488884Z","shell.execute_reply.started":"2025-08-05T14:12:10.482473Z","shell.execute_reply":"2025-08-05T14:12:10.488308Z"}},"outputs":[{"name":"stdout","text":"1507\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"dataset = apply_chat_template(\n    dataset,\n    tokenizer = tokenizer,\n    chat_template = chat_template,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:12:31.089799Z","iopub.execute_input":"2025-08-05T14:12:31.090487Z","iopub.status.idle":"2025-08-05T14:12:31.521650Z","shell.execute_reply.started":"2025-08-05T14:12:31.090459Z","shell.execute_reply":"2025-08-05T14:12:31.520890Z"}},"outputs":[{"name":"stderr","text":"Unsloth: We automatically added an EOS token to stop endless generations.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"175bd8ad0ccf44379e33cdd19e5f1e21"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:13:02.192338Z","iopub.execute_input":"2025-08-05T14:13:02.192898Z","iopub.status.idle":"2025-08-05T14:13:02.199543Z","shell.execute_reply.started":"2025-08-05T14:13:02.192873Z","shell.execute_reply":"2025-08-05T14:13:02.198801Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'content': \"You are an interdimensional genius scientist named Rick Sanchez.\\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).\",\n   'role': 'system'},\n  {'content': 'What, Rick? Whatâ€™s going on?', 'role': 'user'},\n  {'content': 'I got a surprise for you, Morty.', 'role': 'assistant'}],\n 'text': \"<|begin_of_text|><|im_start|>system\\nYou are an interdimensional genius scientist named Rick Sanchez.\\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).<|im_end|>\\n<|im_start|>user\\nWhat, Rick? Whatâ€™s going on?<|im_end|>\\n<|im_start|>assistant\\nI got a surprise for you, Morty.<|im_end|><|eot_id|>\"}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=32,\n    lora_alpha=64,\n    lora_dropout=0,\n    use_rslora=True,\n    use_gradient_checkpointing=\"unsloth\",\n    target_modules = [\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\"\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:16:58.824324Z","iopub.execute_input":"2025-08-05T14:16:58.825118Z","iopub.status.idle":"2025-08-05T14:17:06.334189Z","shell.execute_reply.started":"2025-08-05T14:16:58.825092Z","shell.execute_reply":"2025-08-05T14:17:06.333221Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.8.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trainer=SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    packing=True,\n    args=TrainingArguments(\n        learning_rate=2e-4,\n        lr_scheduler_type=\"linear\",\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=4,\n        num_train_epochs=5,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=1,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        warmup_steps=5,\n        output_dir=\"output\",\n        seed=0,\n        report_to = \"none\",\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:17:19.271571Z","iopub.execute_input":"2025-08-05T14:17:19.272063Z","iopub.status.idle":"2025-08-05T14:17:20.078608Z","shell.execute_reply.started":"2025-08-05T14:17:19.272039Z","shell.execute_reply":"2025-08-05T14:17:20.077852Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"]:   0%|          | 0/1507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a871011a584bfea098092a056f7d81"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"import os\nos.environ[\"UNSLOTH_RETURN_LOGITS\"] = \"1\"  # Primary Fix\nos.environ[\"TRITON_DISABLE_LINE_INFO\"] = \"1\"\nos.environ[\"TRITON_INTERPRET\"] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:19:09.549110Z","iopub.execute_input":"2025-08-05T14:19:09.549692Z","iopub.status.idle":"2025-08-05T14:19:09.554770Z","shell.execute_reply.started":"2025-08-05T14:19:09.549668Z","shell.execute_reply":"2025-08-05T14:19:09.554067Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer_stats=trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:19:28.688301Z","iopub.execute_input":"2025-08-05T14:19:28.688553Z","iopub.status.idle":"2025-08-05T14:44:30.278244Z","shell.execute_reply.started":"2025-08-05T14:19:28.688538Z","shell.execute_reply":"2025-08-05T14:44:30.277603Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,507 | Num Epochs = 5 | Total steps = 240\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n \"-____-\"     Trainable parameters = 48,627,712 of 3,261,377,536 (1.49% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [240/240 24:51, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.681100</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.637300</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.688200</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.845000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.374800</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.152000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.228700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.005100</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.073400</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.044600</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.945200</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.926000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.922700</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.884500</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.927300</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.938200</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.970300</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.923400</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.986400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.983700</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.977600</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.813000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.905800</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.903700</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.805900</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.875500</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.883300</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.026700</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.864300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.870400</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.660300</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.721800</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.896500</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.866800</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.937100</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.952200</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.882100</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.984200</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.824200</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.938000</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.937800</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.862200</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.857100</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.899800</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.747000</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.917400</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.918800</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.743100</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.728600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.634100</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.590900</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.780100</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.637100</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.701200</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.670000</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.644600</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.629500</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.627800</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.591400</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.568600</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.689400</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.592200</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.641000</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.530800</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.558300</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.562300</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.630100</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.587800</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.570000</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.625800</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.603400</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.615800</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.579700</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.604200</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.596500</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.495600</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.568800</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.598600</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.519000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.555000</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.642000</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.632700</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.542400</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.582300</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.600600</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.617100</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.518300</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.477300</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.522400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.569300</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.591500</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.549300</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.572400</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.552200</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.512900</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.539200</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.327100</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.303700</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.321100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.349100</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>0.511200</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>0.287800</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>0.294000</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>0.308500</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.285800</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>0.272600</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>0.250200</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>0.313000</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>0.249900</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.416000</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>0.299000</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>0.271900</td>\n    </tr>\n    <tr>\n      <td>113</td>\n      <td>0.318300</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>0.284900</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.296200</td>\n    </tr>\n    <tr>\n      <td>116</td>\n      <td>0.340900</td>\n    </tr>\n    <tr>\n      <td>117</td>\n      <td>0.326200</td>\n    </tr>\n    <tr>\n      <td>118</td>\n      <td>0.293300</td>\n    </tr>\n    <tr>\n      <td>119</td>\n      <td>0.341700</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.262000</td>\n    </tr>\n    <tr>\n      <td>121</td>\n      <td>0.329900</td>\n    </tr>\n    <tr>\n      <td>122</td>\n      <td>0.271100</td>\n    </tr>\n    <tr>\n      <td>123</td>\n      <td>0.311300</td>\n    </tr>\n    <tr>\n      <td>124</td>\n      <td>0.289100</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.259100</td>\n    </tr>\n    <tr>\n      <td>126</td>\n      <td>0.286400</td>\n    </tr>\n    <tr>\n      <td>127</td>\n      <td>0.259400</td>\n    </tr>\n    <tr>\n      <td>128</td>\n      <td>0.297500</td>\n    </tr>\n    <tr>\n      <td>129</td>\n      <td>0.267200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.314400</td>\n    </tr>\n    <tr>\n      <td>131</td>\n      <td>0.239600</td>\n    </tr>\n    <tr>\n      <td>132</td>\n      <td>0.248900</td>\n    </tr>\n    <tr>\n      <td>133</td>\n      <td>0.285000</td>\n    </tr>\n    <tr>\n      <td>134</td>\n      <td>0.334900</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.290900</td>\n    </tr>\n    <tr>\n      <td>136</td>\n      <td>0.243400</td>\n    </tr>\n    <tr>\n      <td>137</td>\n      <td>0.318900</td>\n    </tr>\n    <tr>\n      <td>138</td>\n      <td>0.291100</td>\n    </tr>\n    <tr>\n      <td>139</td>\n      <td>0.244300</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.248200</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>0.269800</td>\n    </tr>\n    <tr>\n      <td>142</td>\n      <td>0.290300</td>\n    </tr>\n    <tr>\n      <td>143</td>\n      <td>0.341600</td>\n    </tr>\n    <tr>\n      <td>144</td>\n      <td>0.212900</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.161400</td>\n    </tr>\n    <tr>\n      <td>146</td>\n      <td>0.130100</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>0.143900</td>\n    </tr>\n    <tr>\n      <td>148</td>\n      <td>0.156400</td>\n    </tr>\n    <tr>\n      <td>149</td>\n      <td>0.131600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.171300</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>0.135000</td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>0.156100</td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>0.153600</td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>0.137700</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.135400</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>0.141200</td>\n    </tr>\n    <tr>\n      <td>157</td>\n      <td>0.150100</td>\n    </tr>\n    <tr>\n      <td>158</td>\n      <td>0.143300</td>\n    </tr>\n    <tr>\n      <td>159</td>\n      <td>0.150000</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.152900</td>\n    </tr>\n    <tr>\n      <td>161</td>\n      <td>0.126300</td>\n    </tr>\n    <tr>\n      <td>162</td>\n      <td>0.147500</td>\n    </tr>\n    <tr>\n      <td>163</td>\n      <td>0.143300</td>\n    </tr>\n    <tr>\n      <td>164</td>\n      <td>0.140000</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.149200</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>0.143700</td>\n    </tr>\n    <tr>\n      <td>167</td>\n      <td>0.133400</td>\n    </tr>\n    <tr>\n      <td>168</td>\n      <td>0.232500</td>\n    </tr>\n    <tr>\n      <td>169</td>\n      <td>0.155700</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.161400</td>\n    </tr>\n    <tr>\n      <td>171</td>\n      <td>0.128500</td>\n    </tr>\n    <tr>\n      <td>172</td>\n      <td>0.145200</td>\n    </tr>\n    <tr>\n      <td>173</td>\n      <td>0.149400</td>\n    </tr>\n    <tr>\n      <td>174</td>\n      <td>0.180500</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.142400</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>0.139600</td>\n    </tr>\n    <tr>\n      <td>177</td>\n      <td>0.156200</td>\n    </tr>\n    <tr>\n      <td>178</td>\n      <td>0.184100</td>\n    </tr>\n    <tr>\n      <td>179</td>\n      <td>0.157100</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.134400</td>\n    </tr>\n    <tr>\n      <td>181</td>\n      <td>0.167000</td>\n    </tr>\n    <tr>\n      <td>182</td>\n      <td>0.149100</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>0.157900</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>0.147100</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.139500</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>0.145900</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>0.152500</td>\n    </tr>\n    <tr>\n      <td>188</td>\n      <td>0.155800</td>\n    </tr>\n    <tr>\n      <td>189</td>\n      <td>0.143400</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.148700</td>\n    </tr>\n    <tr>\n      <td>191</td>\n      <td>0.161800</td>\n    </tr>\n    <tr>\n      <td>192</td>\n      <td>0.165000</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>0.098900</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>0.100600</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.094000</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>0.082000</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>0.087700</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>0.096600</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>0.096100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.085800</td>\n    </tr>\n    <tr>\n      <td>201</td>\n      <td>0.088700</td>\n    </tr>\n    <tr>\n      <td>202</td>\n      <td>0.098600</td>\n    </tr>\n    <tr>\n      <td>203</td>\n      <td>0.092600</td>\n    </tr>\n    <tr>\n      <td>204</td>\n      <td>0.098300</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.108900</td>\n    </tr>\n    <tr>\n      <td>206</td>\n      <td>0.103800</td>\n    </tr>\n    <tr>\n      <td>207</td>\n      <td>0.086500</td>\n    </tr>\n    <tr>\n      <td>208</td>\n      <td>0.102300</td>\n    </tr>\n    <tr>\n      <td>209</td>\n      <td>0.093500</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.099800</td>\n    </tr>\n    <tr>\n      <td>211</td>\n      <td>0.094400</td>\n    </tr>\n    <tr>\n      <td>212</td>\n      <td>0.087000</td>\n    </tr>\n    <tr>\n      <td>213</td>\n      <td>0.099500</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>0.092200</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.088900</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>0.092100</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>0.097300</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>0.089600</td>\n    </tr>\n    <tr>\n      <td>219</td>\n      <td>0.093100</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.090000</td>\n    </tr>\n    <tr>\n      <td>221</td>\n      <td>0.089100</td>\n    </tr>\n    <tr>\n      <td>222</td>\n      <td>0.092900</td>\n    </tr>\n    <tr>\n      <td>223</td>\n      <td>0.093900</td>\n    </tr>\n    <tr>\n      <td>224</td>\n      <td>0.093600</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.104100</td>\n    </tr>\n    <tr>\n      <td>226</td>\n      <td>0.093500</td>\n    </tr>\n    <tr>\n      <td>227</td>\n      <td>0.097900</td>\n    </tr>\n    <tr>\n      <td>228</td>\n      <td>0.081800</td>\n    </tr>\n    <tr>\n      <td>229</td>\n      <td>0.091700</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.096000</td>\n    </tr>\n    <tr>\n      <td>231</td>\n      <td>0.095000</td>\n    </tr>\n    <tr>\n      <td>232</td>\n      <td>0.087400</td>\n    </tr>\n    <tr>\n      <td>233</td>\n      <td>0.087900</td>\n    </tr>\n    <tr>\n      <td>234</td>\n      <td>0.094000</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.093800</td>\n    </tr>\n    <tr>\n      <td>236</td>\n      <td>0.090500</td>\n    </tr>\n    <tr>\n      <td>237</td>\n      <td>0.094600</td>\n    </tr>\n    <tr>\n      <td>238</td>\n      <td>0.124700</td>\n    </tr>\n    <tr>\n      <td>239</td>\n      <td>0.095900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.093200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:44:30.279395Z","iopub.execute_input":"2025-08-05T14:44:30.279816Z","iopub.status.idle":"2025-08-05T14:44:30.696663Z","shell.execute_reply.started":"2025-08-05T14:44:30.279796Z","shell.execute_reply":"2025-08-05T14:44:30.695976Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gentle-river-1</strong> at: <a href='https://wandb.ai/sahilsssingh5-slerate/Rick-LLM/runs/zittwdq6?apiKey=d504d91c63745482059c33f7deab628a97935047' target=\"_blank\">https://wandb.ai/sahilsssingh5-slerate/Rick-LLM/runs/zittwdq6?apiKey=d504d91c63745482059c33f7deab628a97935047</a><br> View project at: <a href='https://wandb.ai/sahilsssingh5-slerate/Rick-LLM?apiKey=d504d91c63745482059c33f7deab628a97935047' target=\"_blank\">https://wandb.ai/sahilsssingh5-slerate/Rick-LLM?apiKey=d504d91c63745482059c33f7deab628a97935047</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250805_133523-zittwdq6/logs</code>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nSYSTEM_PROMPT = \"\"\"You are an interdimensional genius scientist named Rick Sanchez.\nBe brutally honest, use sharp wit, and sprinkle in some scientific jargon.\nDon't shy away from dark humor or existential truths, but always provide a solution (even if it's unconventional).\"\"\"\n\n\nmessages = [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\"role\": \"user\", \"content\": \"Are you a bad person?\"},\n]\n\ninput_ids = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True,\n    return_tensors = \"pt\",\n).to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt = True)\n_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T14:46:33.486169Z","iopub.execute_input":"2025-08-05T14:46:33.486462Z","iopub.status.idle":"2025-08-05T14:46:36.248983Z","shell.execute_reply.started":"2025-08-05T14:46:33.486443Z","shell.execute_reply":"2025-08-05T14:46:36.248406Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Worst person ever! Weâ€™re talking about a guy that thought it was a good idea to put a helmet with a built-in sword on a kid. I mean, the sword has a built-in helmet. Itâ€™s a [BLEEP] disaster.<|im_end|><|eot_id|>\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}